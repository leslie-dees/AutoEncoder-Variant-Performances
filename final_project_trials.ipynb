{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b484a1-644f-434a-aa5a-9d6199e765e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b923f27a-7df5-46cd-9b27-cdbd340fcf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation of a random gaussian noise transform to artificially damage the dataset\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856614d6-0e4b-4d56-b846-e1b860cdd7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Values of noise for the gaussian transforms that are experimented on for image reconstruction\n",
    "sigmas = [0.05, 0.25, 0.5]\n",
    "train_loaders = {}\n",
    "valid_loaders = {}\n",
    "test_loaders = {}\n",
    "no_noise_test_loaders = {}\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "for sigma in sigmas:\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         #transforms.GaussianBlur(kernel_size = (7,7), sigma=percent),\n",
    "         AddGaussianNoise(0., sigma)\n",
    "         #transforms.RandomErasing(p=1, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),\n",
    "    ])\n",
    "    \n",
    "    transform_no_noise = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    dataset = torchvision.datasets.KMNIST(root='../data', train=True, download=True, transform=transform)\n",
    "    test_set = torchvision.datasets.KMNIST(root='../data', train=False, download=True, transform=transform)\n",
    "    no_noise_test = torchvision.datasets.KMNIST(root='../data', train=False, download=True, transform=transform_no_noise)\n",
    "    train_set, val_set = torch.utils.data.random_split(dataset, [48000, 12000])\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    no_noise_test_loader = torch.utils.data.DataLoader(no_noise_test, batch_size = batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    train_loaders[str(sigma)] = train_loader\n",
    "    valid_loaders[str(sigma)] = val_loader\n",
    "    test_loaders[str(sigma)] = test_loader\n",
    "    no_noise_test_loaders[str(sigma)] = no_noise_test_loader\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e287d7e6-0042-459a-8797-60dfdc850e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BVAE(nn.Module):\n",
    "    #Implementation of Beta-VAE, based on standard VAE with Beta parameter = 4\n",
    "    #Beta determined through grid-search of parameters (2, 6)\n",
    "    def __init__(self, n_in, n_hid, z_dim, beta: int=4):\n",
    "        super(BVAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_in, n_hid)\n",
    "        self.fc21 = nn.Linear(n_hid, z_dim)\n",
    "        self.fc22 = nn.Linear(n_hid, z_dim)\n",
    "        self.fc3 = nn.Linear(z_dim, n_hid)\n",
    "        self.fc4 = nn.Linear(n_hid, n_in)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        stdev = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(stdev)\n",
    "        return mu + eps*stdev\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    \n",
    "def beta_loss_function(recon_x, x, mu, logvar, Beta):\n",
    "\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum') # BCE = -Negative Log-likelihood\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) # KL Divergence b/w q_\\phi(z|x) || p(z)\n",
    "    return BCE + Beta*KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad8a4c-041d-4479-9da2-2deda91225a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FAE(nn.Module):\n",
    "    def __init__(self, n_in, n_hid, z_dim,num_classes=10):\n",
    "        super(FAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(n_in, n_hid)\n",
    "        self.fc21 = nn.Linear(n_hid, z_dim)\n",
    "        self.fc22 = nn.Linear(n_hid, z_dim)\n",
    "        self.fc3 = nn.Linear(z_dim, n_hid)\n",
    "        self.fc4 = nn.Linear(n_hid, n_in)\n",
    "\n",
    "    def encode(self, x):\n",
    "\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "\n",
    "        stdev = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(stdev)\n",
    "        return mu + eps*stdev\n",
    "    \n",
    "    def decode(self, z):\n",
    "\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        out = self.fc4(h3)\n",
    "        output = torch.sigmoid(out)\n",
    "        return output\n",
    "    \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "def fisher_loss_function(recon_x, x, mu, logvar, model):\n",
    "    sigma = torch.exp(0.5*logvar)\n",
    "    eps = torch.randn_like(sigma)\n",
    "    z = mu + eps*sigma\n",
    "    \n",
    "    #gradient with respect to z of the derived distribution q(z|x)\n",
    "    A = -eps/sigma\n",
    "    \n",
    "    #derived gradient of the prior standard normal distribution\n",
    "    B = -(z)\n",
    "    \n",
    "    #gradient with respect to z of the ground-truth distribution\n",
    "    C = C_grad(z,x,model)\n",
    "    \n",
    "    #L2 norm of A - B + C\n",
    "    ABC = torch.linalg.norm(A-B+C,ord=2)**2\n",
    "    \n",
    "    #l2 norm of the difference between original images and image reconstructions\n",
    "    D = torch.linalg.norm(x - recon_x,ord=2)**2\n",
    "    \n",
    "    #L2 norm of the gradient with respect to x of the derived distribution q(z|X)\n",
    "    E = torch.linalg.norm(E_grad(z,x,model),ord=2)**2\n",
    "    \n",
    "    loss = ABC + D + E\n",
    "    #loss = D\n",
    "    #print(torch.sum(A).item(),torch.sum(B).item(),torch.sum(C).item(),D.item(),E.item())\n",
    "    return loss\n",
    "\n",
    "def C_grad(z,x,model):\n",
    "    #representation of a point estimate gradient from the ground-truth distribution given a sampled value of z\n",
    "    x = x.detach()\n",
    "    z = z.detach()\n",
    "    z.requires_grad = True #it is necessary to detach so that we can set z to require grad within the function, else it returns None\n",
    "    p_x_z = model.decode(z) #using a sampled z latent vector, it is decoded into a reconstructed image\n",
    "    p_x_z_distr = F.binary_cross_entropy(p_x_z, x, reduction='sum') #cross entropy loss is used to calculate the negative log likelihood\n",
    "    p_x_z_distr.backward() #sets the stage for taking the gradient of this function\n",
    "    return z.grad #take the gradient with respect to z as specified by C\n",
    "\n",
    "def E_grad(z,x,model):\n",
    "    #\n",
    "    x = x.detach()\n",
    "    z = z.detach()\n",
    "    x.requires_grad = True #similarly need to detach in order to require grad so its not None\n",
    "    mu,logvar = model.encode(x) #encode the input image into the parameters that define the latent distribution\n",
    "    \n",
    "    #The multivariate normal is able to create a distrbution for each batch\n",
    "    #Each batch needs its own mu of size 20, and covariance matrix of size 20x20\n",
    "    diag = []\n",
    "    for b in logvar: #for each batch\n",
    "        var = torch.exp(b) #we have logvar so convert to variance which is what goes on the diagonal of covariance matrix\n",
    "        d = torch.diag(var).detach().cpu().numpy().tolist() #use diag to convert 20 vector into diagonal of 20x20 matrix\n",
    "        diag += [d] #add batch diagonal to list\n",
    "    diag = torch.FloatTensor(np.array(diag)).to(device) #convert back to a tensor\n",
    "    \n",
    "    m = MultivariateNormal(mu,diag) #create the normal gaussian distribution for all batches\n",
    "    loglike = m.log_prob(z) #calculate the log likelihood of the distribution\n",
    "    loglike.mean().backward() #take the mean across all of the batches because loss needs to be a scalar\n",
    "    return x.grad # use this to calculate gradient with respect to x as needed for E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f214f6-d4f3-4242-acd2-75a7bfcbefa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher_train(model, device, train_loader, valid_loader, optimizer, epoch):\n",
    "    #Used to train and validation the fisher autoencoder model\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.view(data.size(0),-1)\n",
    "        data = data.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output, mu, logvar = model(data)\n",
    "        loss = fisher_loss_function(output, data, mu, logvar, model)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        if batch_idx % (len(train_loader)//2) == 0:\n",
    "            print('Train({})[{:.0f}%]: Loss: {:.4f}'.format(\n",
    "                epoch, 100. * batch_idx / len(train_loader), train_loss/(batch_idx+1)))\n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    #with torch.no_grad():\n",
    "    for data, target in valid_loader:\n",
    "        data = data.view(data.size(0),-1)\n",
    "        data = data.to(device)\n",
    "        output, mu, logvar = model(data)\n",
    "        loss = fisher_loss_function(output, data, mu, logvar, model)\n",
    "        valid_loss += loss.item() # sum up batch loss\n",
    "    valid_loss = (valid_loss*batch_size)/len(val_loader.dataset)\n",
    "    print('Valid({}): Loss: {:.4f}'.format(\n",
    "        epoch, valid_loss))\n",
    "    return valid_loss\n",
    "\n",
    "def fisher_test(model, device, test_loader, epoch):\n",
    "    #used to test the ability of the fisher autoencoder to reconstruct on a test dataset\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    for data, target in test_loader:\n",
    "        data = data.view(data.size(0),-1)\n",
    "        data = data.to(device)\n",
    "        output, mu, logvar = model(data)\n",
    "        loss = fisher_loss_function(output, data, mu, logvar, model)\n",
    "        test_loss += loss.item() # sum up batch loss\n",
    "    test_loss = (test_loss*batch_size)/len(test_loader.dataset)\n",
    "    print('Test({}): Loss: {:.4f}'.format(\n",
    "        epoch, test_loss))\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e10ef-2968-4867-9d89-1268ce93c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_train(model, device, train_loader, valid_loader, optimizer, epoch, Beta=4):\n",
    "    #Used to train and validate the beta VAE model\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.view(data.size(0),-1)\n",
    "        data = data.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output, mu, logvar = model(data)\n",
    "        loss = beta_loss_function(output, data, mu, logvar, Beta)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        if batch_idx % (len(train_loader)//2) == 0:\n",
    "            print('Train({})[{:.0f}%]: Loss: {:.4f}'.format(\n",
    "                epoch, 100. * batch_idx / len(train_loader), train_loss/(batch_idx+1)))\n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in valid_loader:\n",
    "            data = data.view(data.size(0),-1)\n",
    "            data = data.to(device)\n",
    "            output, mu, logvar = model(data)\n",
    "            loss = beta_loss_function(output, data, mu, logvar, Beta)\n",
    "            valid_loss += loss.item() # sum up batch loss\n",
    "    valid_loss = (valid_loss*batch_size)/len(val_loader.dataset)\n",
    "    print('Valid({}): Loss: {:.4f}'.format(\n",
    "        epoch, valid_loss))\n",
    "    return valid_loss\n",
    "\n",
    "def test_beta(model, device, test_loader, epoch, Beta):\n",
    "    #Used to test the abilty of the beta autoencoder to reconstruct on a test dataset\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data = data.view(data.size(0),-1)\n",
    "        data = data.to(device)\n",
    "        output, mu, logvar = model(data)\n",
    "        loss = beta_loss_function(output, data, mu, logvar, Beta)\n",
    "        test_loss += loss.item() # sum up batch loss\n",
    "    test_loss = (test_loss*batch_size)/len(test_loader.dataset)\n",
    "    print('Test({}): Loss: {:.4f}'.format(\n",
    "        epoch, test_loss))\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7df0e34-43f2-4ad6-93e9-5a19b9a2cfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "num_epochs = 10\n",
    "lr = 0.001\n",
    "n_in = 28*28\n",
    "n_hid = 400\n",
    "z_dim = 20\n",
    "\n",
    "#Tuned from 2,6 by 0.25: 4 was the lowest validation loss\n",
    "Beta = 4\n",
    "\n",
    "device = torch.device(device)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1754d3-a0a4-4236-b609-daac80ee3f16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dict of validation scores for each standard deviation value, will be used to plot validation score over epoch for different noise levels\n",
    "fisher_validation_scores = {}\n",
    "\n",
    "#Code to train each model\n",
    "#Need to change the model type and loss function for obtaining results for different models\n",
    "#Also need to change saved model paths\n",
    "for key in sigmas:\n",
    "    valid_scores = []\n",
    "    key = str(key)\n",
    "    train_loader = train_loaders[key]\n",
    "    valid_loader = valid_loaders[key]\n",
    "    test_loader = test_loaders[key]\n",
    "    #change model for fisher\n",
    "    model = FAE(n_in, n_hid, z_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        min_validation_loss = np.inf\n",
    "        #change train function for fisher\n",
    "        val_loss = fisher_train(model, device, train_loader, valid_loader, optimizer, epoch)\n",
    "        valid_scores.append(val_loss)\n",
    "        if abs(min_validation_loss) > abs(val_loss):\n",
    "            min_validation_loss = val_loss\n",
    "            #change model location for fisher\n",
    "            torch.save(model.state_dict(), str(key)+'_saved_fisher_model.pth')\n",
    "    model_best_state_dict = torch.load(str(key)+'_saved_fisher_model.pth')\n",
    "    model2 = FAE(n_in, n_hid, z_dim).to(device)\n",
    "    model2.load_state_dict(model_best_state_dict)\n",
    "    test_loss = fisher_test(model2, device, test_loader, epoch)\n",
    "    print(test_loss)\n",
    "    fisher_validation_scores[key] = valid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb117945-db80-4c9f-ad1a-15e070646abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this to plot validation loss over different epochs\n",
    "test = np.arange(1, num_epochs+1, 1)\n",
    "for key in fisher_validation_scores:\n",
    "    plt.plot(test, fisher_validation_scores[key], label = key)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Validation Loss\")\n",
    "plt.title(\"Validation Loss over Epochs For Fisher AE Gaussian Noise\")\n",
    "plt.savefig('fisher_ae_blackbox.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85382cef-afb6-4335-80a5-8d30d789a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot in order top to bottom: Original Image, Gaussian Image, Reconstructed image\n",
    "\n",
    "for key in sigmas:\n",
    "    title = \"Image Reconstruction: N(0, \"+str(key)+\")\"\n",
    "    key = str(key)\n",
    "    test_data, test_target = next(iter(test_loaders[key]))\n",
    "    nn_test_data, nn_test_target = next(iter(no_noise_test_loaders[key]))\n",
    "    model_best_state_dict = torch.load(str(key)+'_saved_fisher_model.pth')\n",
    "    model_best = FAE(n_in, n_hid, z_dim).to(device)\n",
    "    model_best.load_state_dict(model_best_state_dict)\n",
    "    test_data = test_data.to(device)\n",
    "    test_data = test_data.to('cpu')\n",
    "\n",
    "    data = test_data\n",
    "    data_size = data.size()\n",
    "    data = data.view(data.size(0),-1).to(device)\n",
    "    output, _, _ = model_best(data)\n",
    "    output = output.detach()\n",
    "    output = output.to('cpu')\n",
    "    \n",
    "    f, axarr = plt.subplots(3,1, figsize=(15, 15)) \n",
    "    f.suptitle(title, fontsize = 20)\n",
    "    f.tight_layout()\n",
    "    # use the created array to output your multiple images. In this case I have stacked 4 images vertically\n",
    "    axarr[1].imshow(test_data[3][0])\n",
    "    axarr[0].imshow(nn_test_data[3][0])\n",
    "    axarr[2].imshow(output[3].reshape(28, 28))\n",
    "    plt.savefig('full_figure_{}_fisher_blackbox.png'.format(key))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b11d084-e6ef-44b5-a9e2-cd299fa95e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot black box images from the saved gaussian model\n",
    "fig = plt.figure(figsize = (10,3))\n",
    "for dig in range(10):\n",
    "    idx = labels.index(dig)\n",
    "    ax1 = fig.add_subplot(3,10,dig+1)\n",
    "    plt.imshow(nn_test_data[idx][0])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3,10,10+dig+1)\n",
    "    plt.imshow(test_data[idx][0])\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(3,10,20+dig+1)\n",
    "    model_best_state_dict = torch.load(str(key)+'_saved_fisher_model.pth')\n",
    "    model_best = FAE(n_in, n_hid, z_dim).to(device)\n",
    "    model_best.load_state_dict(model_best_state_dict)\n",
    "    output, _, _ = model_best(data)\n",
    "    output = output.detach()\n",
    "    output = output.to('cpu')\n",
    "    plt.imshow(output[idx].reshape(28,28))\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "model_best_state_dict = torch.load(str(0.05)+'_saved_fisher_model.pth')\n",
    "model_best = FAE(n_in, n_hid, z_dim).to(device)\n",
    "model_best.load_state_dict(model_best_state_dict)\n",
    "output, _, _ = model_best(torch.FloatTensor(BBI.reshape(1,784)).to(device))\n",
    "output = output.detach()\n",
    "output = output.to('cpu')\n",
    "plt.imshow(output.reshape(28,28))\n",
    "\n",
    "\n",
    "I = nn_test_data[3][0]\n",
    "BBI = I\n",
    "BBI[15:25,2:12] = 0\n",
    "plt.imshow(BBI)\n",
    "\n",
    "BBIR = BBI\n",
    "BBIR[15:25,2:12] = output.reshape(28,28)[15:25,2:12]\n",
    "plt.imshow(BBIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
